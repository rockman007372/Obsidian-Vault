---
tags:
  - toProcess
course: ES2660
type: content
date: 2024-09-28 Saturday
---

#### 1. What are some of the most pressing issues that arise from the AI race among Big Tech around the world? Illustrate your perspective with concrete examples/case studies from your sector/interest area.

Keywords:
- pressing issues
- AI race among big tech

Context:
- [Arm-race](https://time.com/6255952/ai-impact-chatgpt-microsoft-google/) development:
	- Microsoft and Alphabet-owned Google have shifted their entire corporate strategies in order to seize control of what they believe will become a new infrastructure layer of the economy
	- Microsoft is investing $10 billion in OpenAI, creator of ChatGPT and Dall-E, and announced plans to integrate generative AI into its Office software and search engine, Bing (COPILOT).
	-  Google [declared](https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html) a “code red” corporate emergency in response to the success of ChatGPT and rushed its own search-oriented chatbot, Gemini, to market.
		- Controversies: misinformation

Pressing issues:
- Profits over ethical self-regulation: As companies hurry to improve the tech and profit from the boom, research about keeping these tools safe is taking a back seat

1.  **Algorithmic Bias in Financial Services**
- AI model influencing credit scoring and lending decisions can inherit biases present in historical data that they train on
- A study of AI-driven credit scoring systems in the U.S. revealed biases in lending, with minority applicants more likely to be denied loans or offered worse terms compared to others.
	- An investigation lenders were more likely to deny home loans to people of color than to white people with similar financial characteristics. Specifically, [80% of Black applicants are more likely to be rejected](https://apnews.com/article/lifestyle-technology-business-race-and-ethnicity-mortgages-2d3d40d5751f933a88c1e17063657586 "https://apnews.com/article/lifestyle-technology-business-race-and-ethnicity-mortgages-2d3d40d5751f933a88c1e17063657586"), along with 40% of Latino applicants, and 70% of Native American
	- Recent research from the University of California, Berkeley, showed that an AI-based mortgage lending system charged Black and Hispanic borrowers higher rates than white people for the same loans.

2. **AI-powered market manipulation through collusive trading**
- A 2023 study by professors in university of Wharton
- On one hand, AI **increases trading efficiency**: 
	- solve optimization problems, perform sophisticated trend analysis, free from human's emotional bias 
	- optimize order matching process in trading platforms, ensuring better prices for market participants
	- according to the 2024 HSGAC Majority Committee Staff Report, there has been increased use and reliance on AI in the financial market, particularly by hedge funds, to inform or determine trading decisions.
- However, can lead to collusive behaviours:
	- Interactions between in trading AI can lead to AI equilibrium, where they collude to manipulate the market and compromise market effeciency and competition.
- However, not enough regulations or no tangible solutions:
	- There has been a strong call from the U.S. Congress and regulators to study AI-driven market manipulation and its implications for financial market stability
	- Regulators have not yet clarified how existing anti-trust prevention frameworks apply to AI-powered trading or proposed new measures to address these challenges.

3.  **Widen income disparity**

Some evidence that AI can reduce income inequalities:
- several studies have now found that within certain occupation groups—including [lawyers](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4626276), [software engineers](https://arxiv.org/abs/2302.06590), [customer service agents](https://www.nber.org/papers/w31161), [management consultants](https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf), and [workers performing professional writing tasks](https://www.science.org/doi/10.1126/science.adh2586#elettersSection)—the lowest skilled or least experienced workers derive much greater productivity gains from AI than their higher skilled, more experienced counterparts => higher productivity means better wage
- AI can create new jobs 

However,  there are at least two likely mechanisms through which AI could increase inequality:
- In the near-term, AI-driven productivity boosts could be **skewed towards high-income workers**, leaving lower-wage workers behind 
	1. LLM are accessed mostly via chatbots or software built on top of LLMs (coding assistant, legal research assistant) 
	2. people best positioned to **benefit** are those who interact with software regularly
	3. those who work in labour-intensive industry, trade and services have less access points.
- In the slightly longer term, AI-driven labor automation could increase the share of income going to capital at the expense of the labor share => Invest in AI to cut labour costs
	1.  [Klarna](https://www.klarna.com/us/), a Swedish fintech company, reported that their AI system was [performing the work of 700 customer service agents](https://www.forbes.com/sites/jackkelly/2024/03/04/klarnas-ai-assistant-is-doing-the-job-of-700-workers-company-says/?sh=62a33a8717ae) about a year after they laid off 700 of their employees.
	2. Advances in AI capabilities make equivalent human skills less scarce, the wage premium for those skills should be expected to decrease as AI improves


> "These ramifications stem from a technology that, for the first time in history, is being developed with the intent to not only perform current human tasks but also to execute _all possible cognitive work_—including newly invented tasks—more effectively than humans can and at a lower cost."


#### 2. Can pausing AI development address those issues? Drawing from your expert area, what should be done to foster responsible and accountable AI development?

- not sustainable and not practical
	- AI is alr proven to be very efficient at solving financial issues and generate profits for companies
		- embedded in **key financial operations**, such as high-frequency trading, risk assessment, fraud detection, and market predictions.
		- Paypal and Stripe rely on AI t detect detect fraudulent transactions, which save them billions of dollars
		- Paypal use AI to boost authorization rate (percentage of transactions that pass the authorization process). High authorization rate = high revenues for online merchants. 
			- reasons for payment failures: wrong payment type, incorrect info, insufficient funds, system outage....
			- ai predict and addresses these issues. Can also identify good transactions, letting Paypal stands in for user with their purchases first.
	- AI is a **global technology**, and countries are competing to lead in its development. Ceasing development in one country won’t stop other nations from advancing their AI capabilities. This could result in **uneven technological advancement** and create **security risks** for countries that fall behind.
- Instead of pausing, a more effective approach is to foster responsible development through collaborative efforts between the private sector and regulators
	- Regulatory Sandboxes: **a framework set up by a financial sector regulator to allow small-scale, live testing of innovations by private firms in a controlled environment under the regulator's supervision**.
		- Fintech Regulatory Sandbox in Singapore: MAS relax specific legal and regulatory requirements which the sandbox entity will otherwise be subject to, for the duration of the sandbox.
	- **Transparent AI Audits**: Big Tech and financial firms should adopt **internal and third-party audits** of AI systems, particularly those impacting credit scoring, investments, or fraud detection.
		- **Goldman Sachs** are investing in explainable AI (XAI), which provides transparency into AI decision-making processes. AI is typically a blackbox, in goes input, out goes output. XAI tries to shed light on the internal decision-making process of AI. Goldman Sachs uses XAI to assess the credit risk of loan applicants so that they can make more fair and informed decisions after reviewing the model's decision. 




## Discussion

**Jun wei** (transport)
2 developments:
- self-driving cars: tesla...
	- safety risks
		- Uber accident, road crosser hit by autonomous vehicle
	- data privacy

- smart logistics and delivery
	- trial autonomous vehicles: truck and drone
	- job displacement

**Joel** (healthcare)
- patient data 

> me

**Kheng Yang** (education)
- not enough time for regulations
- too much reliance for students => becomes a crutch
- 