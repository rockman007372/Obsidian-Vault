
Normalization is **another method** besides Gradient Descent to find the **weights** of hypothesis in order to find the global minimum / minimize loss!

Suppose we have  m examples: $$(x^{(1)}, y^{(1)}), \cdot \cdot \cdot , (x^{(m)}, y^{(m)}))$$
and n features:
$$x^{(i)} = 
\begin{pmatrix}
x^{(i)}_{0} \\
x^{(i)}_{1} \\
\vdots \\
x^{(i)}_{n}
\end{pmatrix}$$
Apply normalization equation:

![[Regression 2022-09-20 00.26.21.excalidraw]]